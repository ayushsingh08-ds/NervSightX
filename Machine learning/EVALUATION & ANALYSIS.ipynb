{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea09eda-75d1-458b-8572-0221291c8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & paths\n",
    "import numpy as np, pandas as pd, joblib, json, os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, average_precision_score,\n",
    "                             precision_score, recall_score, f1_score, accuracy_score,\n",
    "                             confusion_matrix, brier_score_loss)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "ROOT = Path(\"dreaddit_cv_raw_splits\")\n",
    "SEL_DIR = ROOT / \"selected_features\"\n",
    "MODEL_ROOT = Path(\"Machine learning\") / \"models\"\n",
    "TRAIN_CSV = ROOT / \"train_raw_with_clean_text.csv\"\n",
    "TEST_CSV  = ROOT / \"test_frozen_raw_with_clean_text.csv\"\n",
    "X_train_sel_path = SEL_DIR / \"X_train_fused_selected.npy\"\n",
    "X_test_sel_path  = SEL_DIR / \"X_test_fused_selected.npy\"\n",
    "# models to load — change if different\n",
    "models_to_evaluate = {\n",
    "    \"logreg\": MODEL_ROOT / \"logreg\" / \"oof_predictions.csv\",\n",
    "    \"svm\": MODEL_ROOT / \"svm_fast\" / \"oof_predictions.csv\",\n",
    "    \"rf\": MODEL_ROOT / \"rf_baseline\" / \"oof_predictions.csv\",\n",
    "    \"rf_tuned\": MODEL_ROOT / \"rf_tuned_corrected\" / \"rf_tuned_model_corrected.joblib\",\n",
    "    \"lgbm\": MODEL_ROOT / \"lgbm\" / \"oof_predictions.csv\",\n",
    "    \"lgbm_tuned\": MODEL_ROOT / \"lgbm_tuned_quick\" / \"lgbm_tuned_test_metrics.json\"\n",
    "}\n",
    "# outputs\n",
    "OUT = Path(\"dreaddit_analysis_outputs\"); OUT.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007df6a6-47a6-48e2-b91d-de4e6e4f0737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orig_index', 'social_timestamp', 'social_karma', 'syntax_ari', 'lex_liwc_WC', 'lex_liwc_Analytic', 'lex_liwc_Clout', 'lex_liwc_Authentic', 'lex_liwc_Tone', 'lex_liwc_WPS', 'lex_liwc_Sixltr', 'lex_liwc_Dic', 'lex_liwc_function', 'lex_liwc_pronoun', 'lex_liwc_ppron', 'lex_liwc_i', 'lex_liwc_we', 'lex_liwc_you', 'lex_liwc_shehe', 'lex_liwc_they', 'lex_liwc_ipron', 'lex_liwc_article', 'lex_liwc_prep', 'lex_liwc_auxverb', 'lex_liwc_adverb', 'lex_liwc_conj', 'lex_liwc_negate', 'lex_liwc_verb', 'lex_liwc_adj', 'lex_liwc_compare', 'lex_liwc_interrog', 'lex_liwc_number', 'lex_liwc_quant', 'lex_liwc_affect', 'lex_liwc_posemo', 'lex_liwc_negemo', 'lex_liwc_anx', 'lex_liwc_anger', 'lex_liwc_sad', 'lex_liwc_social', 'lex_liwc_family', 'lex_liwc_friend', 'lex_liwc_female', 'lex_liwc_male', 'lex_liwc_cogproc', 'lex_liwc_insight', 'lex_liwc_cause', 'lex_liwc_discrep', 'lex_liwc_tentat', 'lex_liwc_certain', 'lex_liwc_differ', 'lex_liwc_percept', 'lex_liwc_see', 'lex_liwc_hear', 'lex_liwc_feel', 'lex_liwc_bio', 'lex_liwc_body', 'lex_liwc_health', 'lex_liwc_sexual', 'lex_liwc_ingest', 'lex_liwc_drives', 'lex_liwc_affiliation', 'lex_liwc_achieve', 'lex_liwc_power', 'lex_liwc_reward', 'lex_liwc_risk', 'lex_liwc_focuspast', 'lex_liwc_focuspresent', 'lex_liwc_focusfuture', 'lex_liwc_relativ', 'lex_liwc_motion', 'lex_liwc_space', 'lex_liwc_time', 'lex_liwc_work', 'lex_liwc_leisure', 'lex_liwc_home', 'lex_liwc_money', 'lex_liwc_relig', 'lex_liwc_death', 'lex_liwc_informal', 'lex_liwc_swear', 'lex_liwc_netspeak', 'lex_liwc_assent', 'lex_liwc_nonflu', 'lex_liwc_filler', 'lex_liwc_AllPunc', 'lex_liwc_Period', 'lex_liwc_Comma', 'lex_liwc_Colon', 'lex_liwc_SemiC', 'lex_liwc_QMark', 'lex_liwc_Exclam', 'lex_liwc_Dash', 'lex_liwc_Quote', 'lex_liwc_Apostro', 'lex_liwc_Parenth', 'lex_liwc_OtherP', 'lex_dal_max_pleasantness', 'lex_dal_max_activation', 'lex_dal_max_imagery', 'lex_dal_min_pleasantness', 'lex_dal_min_activation', 'lex_dal_min_imagery', 'lex_dal_avg_activation', 'lex_dal_avg_imagery', 'lex_dal_avg_pleasantness', 'social_upvote_ratio', 'social_num_comments', 'syntax_fk_grade', 'sentiment', 'char_len', 'token_len', 'label', 'clean_text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_index</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>lex_liwc_WC</th>\n",
       "      <th>lex_liwc_Analytic</th>\n",
       "      <th>lex_liwc_Clout</th>\n",
       "      <th>lex_liwc_Authentic</th>\n",
       "      <th>lex_liwc_Tone</th>\n",
       "      <th>lex_liwc_WPS</th>\n",
       "      <th>...</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>char_len</th>\n",
       "      <th>token_len</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>685</td>\n",
       "      <td>1493430482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898088</td>\n",
       "      <td>65</td>\n",
       "      <td>34.30</td>\n",
       "      <td>17.79</td>\n",
       "      <td>99.00</td>\n",
       "      <td>95.12</td>\n",
       "      <td>16.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50588</td>\n",
       "      <td>1.89577</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1.433824</td>\n",
       "      <td>0.063228</td>\n",
       "      <td>340</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>what are you gonna do with that strange lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>532</td>\n",
       "      <td>1516372493</td>\n",
       "      <td>0</td>\n",
       "      <td>4.484242</td>\n",
       "      <td>91</td>\n",
       "      <td>11.43</td>\n",
       "      <td>18.97</td>\n",
       "      <td>81.48</td>\n",
       "      <td>11.53</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43846</td>\n",
       "      <td>1.86702</td>\n",
       "      <td>0.47</td>\n",
       "      <td>17</td>\n",
       "      <td>4.655523</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>494</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>but what should i say? part of me wants to tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>1524175905</td>\n",
       "      <td>2</td>\n",
       "      <td>7.011905</td>\n",
       "      <td>89</td>\n",
       "      <td>41.27</td>\n",
       "      <td>28.71</td>\n",
       "      <td>66.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41053</td>\n",
       "      <td>1.83995</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9</td>\n",
       "      <td>7.441484</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>hey guys i have ptsd from years of emotional a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507</td>\n",
       "      <td>1515552336</td>\n",
       "      <td>1</td>\n",
       "      <td>3.404286</td>\n",
       "      <td>40</td>\n",
       "      <td>11.24</td>\n",
       "      <td>77.33</td>\n",
       "      <td>86.07</td>\n",
       "      <td>25.77</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.48108</td>\n",
       "      <td>1.87271</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262190</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>230</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>we had 2 classes together so we spent a few ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465</td>\n",
       "      <td>1541796675</td>\n",
       "      <td>10</td>\n",
       "      <td>7.428889</td>\n",
       "      <td>75</td>\n",
       "      <td>40.12</td>\n",
       "      <td>21.18</td>\n",
       "      <td>91.75</td>\n",
       "      <td>25.77</td>\n",
       "      <td>15.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.58095</td>\n",
       "      <td>1.84232</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>7.626765</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>437</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>it s really just standard issue big corporatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig_index  social_timestamp  social_karma  syntax_ari  lex_liwc_WC  \\\n",
       "0         685        1493430482             1    0.898088           65   \n",
       "1         532        1516372493             0    4.484242           91   \n",
       "2         268        1524175905             2    7.011905           89   \n",
       "3         507        1515552336             1    3.404286           40   \n",
       "4         465        1541796675            10    7.428889           75   \n",
       "\n",
       "   lex_liwc_Analytic  lex_liwc_Clout  lex_liwc_Authentic  lex_liwc_Tone  \\\n",
       "0              34.30           17.79               99.00          95.12   \n",
       "1              11.43           18.97               81.48          11.53   \n",
       "2              41.27           28.71               66.74           1.00   \n",
       "3              11.24           77.33               86.07          25.77   \n",
       "4              40.12           21.18               91.75          25.77   \n",
       "\n",
       "   lex_liwc_WPS  ...  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "0         16.25  ...              1.50588                   1.89577   \n",
       "1         15.17  ...              1.43846                   1.86702   \n",
       "2         17.80  ...              1.41053                   1.83995   \n",
       "3          8.00  ...              1.48108                   1.87271   \n",
       "4         15.00  ...              1.58095                   1.84232   \n",
       "\n",
       "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \\\n",
       "0                 0.67                    0         1.433824   0.063228   \n",
       "1                 0.47                   17         4.655523   0.068519   \n",
       "2                 0.75                    9         7.441484  -0.089286   \n",
       "3                 1.00                    1         4.262190   0.164286   \n",
       "4                 0.99                    1         7.626765   0.050000   \n",
       "\n",
       "   char_len  token_len  label  \\\n",
       "0       340         82      0   \n",
       "1       494        107      1   \n",
       "2       500         98      1   \n",
       "3       230         49      1   \n",
       "4       437         87      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  what are you gonna do with that strange lookin...  \n",
       "1  but what should i say? part of me wants to tel...  \n",
       "2  hey guys i have ptsd from years of emotional a...  \n",
       "3  we had 2 classes together so we spent a few ho...  \n",
       "4  it s really just standard issue big corporatio...  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "print(df_test.columns.tolist())\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efecd676-6c93-4ba6-bc99-bda146f16dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rf_tuned_test_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — load true test labels and predictions from chosen models (example: rf_tuned and logreg)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "y_test = df_test['label'].values\n",
    "texts_test = df_test['clean_text'].astype(str).values\n",
    "\n",
    "# helper: load OOF or test preds for a model\n",
    "def load_model_oof(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    df = pd.read_csv(p)\n",
    "    return df\n",
    "\n",
    "# Example: load RF baseline OOF (if you want to evaluate OOFs) and tuned RF test predictions (if available)\n",
    "rf_oof = load_model_oof(MODEL_ROOT / \"rf_baseline\" / \"oof_predictions.csv\")\n",
    "logreg_oof = load_model_oof(MODEL_ROOT / \"logreg\" / \"oof_predictions.csv\")\n",
    "\n",
    "# Load final tuned RF and produce predictions on frozen test\n",
    "rf_tuned = None\n",
    "rt_path = MODEL_ROOT / \"rf_tuned_corrected\" / \"rf_tuned_model_corrected.joblib\"\n",
    "if rt_path.exists():\n",
    "    rf_tuned = joblib.load(rt_path)\n",
    "    if Path(X_test_sel_path).exists():\n",
    "        X_test_sel = np.load(X_test_sel_path)\n",
    "        probs = rf_tuned.predict_proba(X_test_sel)[:,1]\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "        pd.DataFrame({\"clean_text\": texts_test, \"true\": y_test, \"prob_pos\": probs, \"pred\": preds}).to_csv(OUT/\"rf_tuned_test_preds.csv\", index=False)\n",
    "        print(\"Saved rf_tuned_test_preds.csv\")\n",
    "else:\n",
    "    print(\"No tuned RF model found at\", rt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd50a40-882a-418a-9c1e-f826baebf947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF tuned test metrics: {'accuracy': 0.6923076923076923, 'precision': 0.7083333333333334, 'recall': 0.6891891891891891, 'f1': 0.6986301369863014, 'roc_auc': np.float64(0.7751664708186448), 'pr_auc': np.float64(0.7764052923162905), 'brier': np.float64(0.1952257815851556)}\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69        69\n",
      "           1       0.71      0.69      0.70        74\n",
      "\n",
      "    accuracy                           0.69       143\n",
      "   macro avg       0.69      0.69      0.69       143\n",
      "weighted avg       0.69      0.69      0.69       143\n",
      "\n",
      "Confusion matrix (raw):\n",
      " [[48 21]\n",
      " [23 51]]\n",
      "Confusion matrix (normalized):\n",
      " [[0.69565217 0.30434783]\n",
      " [0.31081081 0.68918919]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Core metrics function + compute for rf_tuned (change model variable to evaluate others)\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def compute_core_metrics(y_true, y_pred, y_prob):\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1m = f1_score(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    pr_auc = average_precision_score(y_true, y_prob)  # PR-AUC (AP)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    return {\"accuracy\":acc, \"precision\":prec, \"recall\":rec, \"f1\":f1m, \"roc_auc\":roc_auc, \"pr_auc\":pr_auc, \"brier\":brier}\n",
    "\n",
    "# load rf tuned test preds\n",
    "preds_df = pd.read_csv(OUT/\"rf_tuned_test_preds.csv\")\n",
    "metrics = compute_core_metrics(preds_df[\"true\"].values, preds_df[\"pred\"].values, preds_df[\"prob_pos\"].values)\n",
    "print(\"RF tuned test metrics:\", metrics)\n",
    "\n",
    "# classification report + confusion matrix\n",
    "print(\"\\nClassification report:\\n\", classification_report(preds_df[\"true\"], preds_df[\"pred\"]))\n",
    "cm = confusion_matrix(preds_df[\"true\"], preds_df[\"pred\"])\n",
    "cm_norm = cm.astype(\"float\")/cm.sum(axis=1)[:,None]\n",
    "print(\"Confusion matrix (raw):\\n\", cm)\n",
    "print(\"Confusion matrix (normalized):\\n\", cm_norm)\n",
    "\n",
    "# save metrics.json\n",
    "import json\n",
    "with open(OUT/\"rf_tuned_test_metrics.json\",\"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4784d422-6ebb-4a70-8b6d-a091404e93b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC, PR, calibration plots to dreaddit_analysis_outputs\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — ROC, Precision-Recall, Calibration curve, Brier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "y_true = preds_df[\"true\"].values\n",
    "y_prob = preds_df[\"prob_pos\"].values\n",
    "y_pred = preds_df[\"pred\"].values\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "plt.figure(figsize=(6,4)); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC Curve\"); plt.grid(True)\n",
    "plt.savefig(OUT/\"rf_tuned_roc.png\"); plt.close()\n",
    "\n",
    "# PR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "plt.figure(figsize=(6,4)); plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curve\")\n",
    "plt.savefig(OUT/\"rf_tuned_pr.png\"); plt.close()\n",
    "\n",
    "# Calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
    "plt.figure(figsize=(6,4)); plt.plot(prob_pred, prob_true, marker='o'); plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "plt.xlabel(\"Mean predicted probability\"); plt.ylabel(\"Fraction of positives\"); plt.title(\"Calibration curve\")\n",
    "plt.savefig(OUT/\"rf_tuned_calibration.png\"); plt.close()\n",
    "\n",
    "print(\"Saved ROC, PR, calibration plots to\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e152e1d5-b0b5-4eae-ab9a-22c34352076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap CIs (median, lo, hi): {'f1': (0.6973684210526315, 0.599963503649635, 0.7755102040816326), 'roc_auc': (0.7726642667215938, 0.6952148223871304, 0.843138140798488), 'pr_auc': (0.7821423428898415, 0.66716011744337, 0.8698809417683042)}\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Bootstrap CIs for F1, ROC-AUC, PR-AUC (1000 resamples)\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def bootstrap_ci(y_true, y_prob, n_boot=1000, alpha=0.05):\n",
    "    n = len(y_true)\n",
    "    f1_list, roc_list, pr_list = [], [], []\n",
    "    for i in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        y_t = y_true[idx]; y_p = y_prob[idx]\n",
    "        # choose threshold 0.5 for f1 (could optimize threshold per sample)\n",
    "        y_hat = (y_p >= 0.5).astype(int)\n",
    "        f1_list.append(f1_score(y_t, y_hat))\n",
    "        try:\n",
    "            roc_list.append(roc_auc_score(y_t, y_p))\n",
    "        except:\n",
    "            roc_list.append(np.nan)\n",
    "        try:\n",
    "            pr_list.append(average_precision_score(y_t, y_p))\n",
    "        except:\n",
    "            pr_list.append(np.nan)\n",
    "    def ci(arr):\n",
    "        arr = np.array(arr)\n",
    "        lo = np.nanpercentile(arr, 100*alpha/2)\n",
    "        hi = np.nanpercentile(arr, 100*(1-alpha/2))\n",
    "        return float(np.nanmedian(arr)), float(lo), float(hi)\n",
    "    return {\"f1\":ci(f1_list), \"roc_auc\":ci(roc_list), \"pr_auc\":ci(pr_list)}\n",
    "\n",
    "ci = bootstrap_ci(y_true, y_prob, n_boot=1000)\n",
    "print(\"Bootstrap CIs (median, lo, hi):\", ci)\n",
    "with open(OUT/\"rf_tuned_bootstrap_cis.json\",\"w\") as f:\n",
    "    json.dump(ci, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14831b9-43bc-464e-b019-8f74b5482202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive tokens (stress): ['my' 'me' 'anxiety' 'feel like' 'don know' 'and' 'do' 'anxious' 'like'\n",
      " 'feel' 'every' 'hard' 'now' 'know' 'am' 'fucking' 'panic' 'my anxiety'\n",
      " 'myself' 'im']\n",
      "Top negative tokens (non-stress): ['you' 'for' 'we' 'your' 'she' 'url' 'their' 'first' 'would' 'more'\n",
      " 'pretty' 'post' 'share' 'if you' 'them' 'homeless' 'who' 'met' 'thanks'\n",
      " 'together']\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — LR coefficient analysis (train a TF-IDF-only LR model for interpretability)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load train/test raw CSVs with clean_text\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "tfidf = joblib.load(ROOT/\"tfidf\"/\"tfidf_vectorizer.joblib\")\n",
    "svd = joblib.load(ROOT/\"svd\"/\"tfidf_svd_200.joblib\")\n",
    "\n",
    "# Train TF-IDF only LR (no SVD) for token-level interpretability\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), max_features=5000, min_df=2)\n",
    "X_train_t = vec.fit_transform(train_df['clean_text'].astype(str).values)\n",
    "X_test_t = vec.transform(test_df['clean_text'].astype(str).values)\n",
    "lr_tok = LogisticRegression(class_weight='balanced', max_iter=2000, solver='liblinear')\n",
    "lr_tok.fit(X_train_t, train_df['label'].values)\n",
    "\n",
    "# save\n",
    "joblib.dump(lr_tok, OUT/\"tfidf_lr.joblib\")\n",
    "joblib.dump(vec, OUT/\"tfidf_tok_vectorizer.joblib\")\n",
    "\n",
    "# coefficients: top positive and negative tokens\n",
    "coef = lr_tok.coef_[0]\n",
    "feat_names = np.array(vec.get_feature_names_out())\n",
    "top_pos = feat_names[np.argsort(coef)[-30:]][::-1]\n",
    "top_neg = feat_names[np.argsort(coef)[:30]]\n",
    "print(\"Top positive tokens (stress):\", top_pos[:20])\n",
    "print(\"Top negative tokens (non-stress):\", top_neg[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bc4b50a-862a-4e4c-a39e-520d19a4640e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m shap_vals \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_train)  \u001b[38;5;66;03m# returns list, 2 classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# global summary\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(OUT\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshap_summary_rf.png\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# local explanation for first test instance\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:664\u001b[0m, in \u001b[0;36msummary_legacy\u001b[1;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    660\u001b[0m             shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    661\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    662\u001b[0m         )\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[1;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    }
   ],
   "source": [
    "# Cell 8 — SHAP (global + local) for RF tuned (tree explainer)\n",
    "# Requires shap package; install if missing: pip install shap\n",
    "import shap\n",
    "rf = joblib.load(rt_path)  # rf_tuned\n",
    "X_train = np.load(SEL_DIR/\"X_train_fused_selected.npy\")\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_vals = explainer.shap_values(X_train)  # returns list, 2 classes\n",
    "# global summary\n",
    "shap.summary_plot(shap_vals[1], X_train, show=False)\n",
    "plt.savefig(OUT/\"shap_summary_rf.png\"); plt.close()\n",
    "# local explanation for first test instance\n",
    "X_test = np.load(SEL_DIR/\"X_test_fused_selected.npy\")\n",
    "shap.force_plot(explainer.expected_value[1], shap_vals[1][0,:], X_train[0,:], matplotlib=True, show=False)\n",
    "plt.savefig(OUT/\"shap_force_sample0.png\"); plt.close()\n",
    "\n",
    "print(\"Saved SHAP plots to\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7e55739-748c-41bf-9004-f30ba25faf5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 9 — LIME token-level interpretation for TF-IDF LR model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# pip install lime\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime_text\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LimeTextExplainer\n\u001b[0;32m      4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeTextExplainer(class_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-stress\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstress\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m predict_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m texts: lr_tok\u001b[38;5;241m.\u001b[39mpredict_proba(vec\u001b[38;5;241m.\u001b[39mtransform(texts))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "# Cell 9 — LIME token-level interpretation for TF-IDF LR model\n",
    "# pip install lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=[\"non-stress\",\"stress\"])\n",
    "predict_fn = lambda texts: lr_tok.predict_proba(vec.transform(texts))\n",
    "i = 0\n",
    "exp = explainer.explain_instance(test_df['clean_text'].iloc[i], predict_fn, num_features=10)\n",
    "print(\"LIME explanation for sample 0:\\n\", exp.as_list())\n",
    "# save for multiple samples\n",
    "lime_out = []\n",
    "for i in range(min(100, len(test_df))):\n",
    "    txt = test_df['clean_text'].iloc[i]\n",
    "    exp = explainer.explain_instance(txt, predict_fn, num_features=10)\n",
    "    lime_out.append({\"idx\": i, \"text\": txt, \"explanation\": exp.as_list()})\n",
    "pd.DataFrame(lime_out).to_csv(OUT/\"lime_test_explanations.csv\", index=False)\n",
    "print(\"Saved LIME explanations to\", OUT/\"lime_test_explanations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5798359-42fd-4843-a546-69b7046cfcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP count: 21 FN count: 23\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'orig_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'orig_index'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df_sample, label \u001b[38;5;129;01min\u001b[39;00m [(fp_sample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m\"\u001b[39m), (fn_sample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, r \u001b[38;5;129;01min\u001b[39;00m df_sample\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 26\u001b[0m         orig_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morig_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     27\u001b[0m         prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob_pos\u001b[39m\u001b[38;5;124m'\u001b[39m]); pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]); true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m         txt \u001b[38;5;241m=\u001b[39m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'orig_index'"
     ]
    }
   ],
   "source": [
    "# Cell 10 — extract FP & FN from tuned RF test preds; save explanations (SHAP + LIME snippets)\n",
    "preds = pd.read_csv(OUT/\"rf_tuned_test_preds.csv\")\n",
    "# find FP, FN\n",
    "fp = preds[(preds['true']==0) & (preds['pred']==1)].copy()\n",
    "fn = preds[(preds['true']==1) & (preds['pred']==0)].copy()\n",
    "print(\"FP count:\", len(fp), \"FN count:\", len(fn))\n",
    "\n",
    "# sample 50 each (or fewer if not available)\n",
    "fp_sample = fp.sample(n=min(50,len(fp)), random_state=42)\n",
    "fn_sample = fn.sample(n=min(50,len(fn)), random_state=42)\n",
    "\n",
    "# For each, compute shap values (local) and LIME explanations using lr_tok/vec\n",
    "# SHAP local: use explainer from earlier and X_test array\n",
    "X_test = np.load(SEL_DIR/\"X_test_fused_selected.npy\")\n",
    "shap_vals_test = explainer.shap_values(X_test)[1]  # class 1 contributions\n",
    "def get_shap_for_index(orig_idx):\n",
    "    # find row index in test array corresponding to orig_index (orig_index stored in test_csv)\n",
    "    tdf = pd.read_csv(TEST_CSV)\n",
    "    pos = tdf.reset_index().set_index('orig_index').loc[orig_idx]['index']\n",
    "    return shap_vals_test[pos]\n",
    "\n",
    "# collect\n",
    "rows = []\n",
    "for df_sample, label in [(fp_sample, \"FP\"), (fn_sample, \"FN\")]:\n",
    "    for _, r in df_sample.iterrows():\n",
    "        orig_idx = int(r['orig_index'])\n",
    "        prob = float(r['prob_pos']); pred = int(r['pred']); true = int(r['true'])\n",
    "        txt = r['text']\n",
    "        # LIME tokens\n",
    "        lime_exp = explainer.explain_instance(txt, predict_fn, num_features=6)\n",
    "        lime_list = lime_exp.as_list()\n",
    "        # SHAP local vector\n",
    "        try:\n",
    "            svals = get_shap_for_index(orig_idx).tolist()\n",
    "        except Exception:\n",
    "            svals = []\n",
    "        rows.append({\n",
    "            \"orig_index\": orig_idx, \"type\": label, \"text\": txt, \"true\": true, \"pred\": pred, \"prob\": prob,\n",
    "            \"lime\": str(lime_list), \"shap_top\": str(sorted(enumerate(svals), key=lambda x: -abs(x[1]))[:10])\n",
    "        })\n",
    "out_df = pd.DataFrame(rows)\n",
    "out_df.to_csv(OUT/\"error_analysis_fp_fn_50_50.csv\", index=False)\n",
    "print(\"Saved error analysis CSV to\", OUT/\"error_analysis_fp_fn_50_50.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5965af2-0f02-4eb2-bee5-3f57ac958ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 — Ablation orchestration\n",
    "# We will run per-configuration training on unique train/test selected arrays and record test metrics.\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# helper to evaluate a pipeline given X_train,y_train,X_test,y_test\n",
    "def eval_model(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    probs = clf.predict_proba(X_test)[:,1]\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    return compute_core_metrics(y_test, preds, probs)\n",
    "\n",
    "# Configs to try:\n",
    "configs = [\n",
    "    {\"name\":\"tfidf_only\",\"use_tfidf\":True,\"use_lex\":False,\"svd_dim\":200},\n",
    "    {\"name\":\"lex_only\",\"use_tfidf\":False,\"use_lex\":True,\"svd_dim\":0},\n",
    "    {\"name\":\"fused_selected\",\"use_tfidf\":True,\"use_lex\":True,\"svd_dim\":200},\n",
    "    {\"name\":\"fused_no_selection\",\"use_tfidf\":True,\"use_lex\":True,\"svd_dim\":200,\"selection\":False}\n",
    "]\n",
    "\n",
    "results = []\n",
    "# load artifacts/vec/svd/lex scaler etc\n",
    "tfidf = joblib.load(ROOT/\"tfidf\"/\"tfidf_vectorizer.joblib\")\n",
    "svd = joblib.load(ROOT/\"svd\"/\"tfidf_svd_200.joblib\")\n",
    "imputer = joblib.load(ROOT/\"lexical\"/\"lex_imputer.joblib\")\n",
    "scaler = joblib.load(ROOT/\"lexical\"/\"lex_scaler.joblib\")\n",
    "selector = joblib.load(ROOT/\"selected_features\"/\"selector_L1.joblib\")\n",
    "lex_cols = pd.read_csv(ROOT/\"lexical\"/\"lexical_columns_list.csv\", header=None)[0].tolist()\n",
    "\n",
    "train_master = pd.read_csv(TRAIN_CSV); test_master = pd.read_csv(TEST_CSV)\n",
    "clean_train = train_master['clean_text'].astype(str).values\n",
    "clean_test  = test_master['clean_text'].astype(str).values\n",
    "\n",
    "# TF-IDF -> SVD transforms\n",
    "X_tfidf_train = tfidf.transform(clean_train); X_tfidf_test = tfidf.transform(clean_test)\n",
    "X_svd_train = svd.transform(X_tfidf_train); X_svd_test = svd.transform(X_tfidf_test)\n",
    "\n",
    "# lexical matrices\n",
    "lex_train = train_master[lex_cols].fillna(0).values\n",
    "lex_test = test_master[lex_cols].fillna(0).values\n",
    "lex_train = scaler.transform(imputer.transform(lex_train))\n",
    "lex_test = scaler.transform(imputer.transform(lex_test))\n",
    "\n",
    "for cfg in configs:\n",
    "    if cfg.get(\"use_tfidf\") and cfg.get(\"use_lex\"):\n",
    "        Xtr = np.hstack([X_svd_train, lex_train])\n",
    "        Xte = np.hstack([X_svd_test, lex_test])\n",
    "    elif cfg.get(\"use_tfidf\"):\n",
    "        Xtr, Xte = X_svd_train, X_svd_test\n",
    "    else:\n",
    "        Xtr, Xte = lex_train, lex_test\n",
    "\n",
    "    # selection ON/OFF\n",
    "    if cfg.get(\"selection\", True):\n",
    "        Xtr_sel = selector.transform(Xtr)\n",
    "        Xte_sel = selector.transform(Xte)\n",
    "    else:\n",
    "        Xtr_sel, Xte_sel = Xtr, Xte\n",
    "\n",
    "    # baseline classifier for ablation: Logistic Regression (simple) and RF for non-linear\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=2000, solver='liblinear')\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=12, class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "\n",
    "    lr_metrics = eval_model(lr, Xtr_sel, train_master['label'].values, Xte_sel, test_master['label'].values)\n",
    "    rf_metrics = eval_model(rf, Xtr_sel, train_master['label'].values, Xte_sel, test_master['label'].values)\n",
    "\n",
    "    results.append({\"config\":cfg[\"name\"], \"lr\":lr_metrics, \"rf\":rf_metrics})\n",
    "    print(\"Completed config:\", cfg[\"name\"])\n",
    "\n",
    "pd.DataFrame(results).to_json(OUT/\"ablation_results.json\", orient='records', indent=2)\n",
    "print(\"Saved ablation results to\", OUT/\"ablation_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e99c9-359d-4118-98c0-2c5a70f467e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
