{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14d34ad-193b-47e0-8aeb-20486dbc5cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found fold dirs: ['fold_01', 'fold_02', 'fold_03', 'fold_04', 'fold_05']\n",
      "\n",
      "Fold 01: X_tr (457, 34), X_val (115, 34), y_tr counts [221 236], y_val counts [56 59]\n",
      " Fold 01 metrics -> acc: 0.7391, prec: 0.6933, rec: 0.8814, f1: 0.7761, auc: 0.8105\n",
      "\n",
      "Fold 02: X_tr (457, 34), X_val (115, 34), y_tr counts [221 236], y_val counts [56 59]\n",
      " Fold 02 metrics -> acc: 0.6696, prec: 0.6207, rec: 0.9153, f1: 0.7397, auc: 0.7778\n",
      "\n",
      "Fold 03: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 03 metrics -> acc: 0.6140, prec: 0.6000, rec: 0.7627, f1: 0.6716, auc: 0.7498\n",
      "\n",
      "Fold 04: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 04 metrics -> acc: 0.7193, prec: 0.7077, rec: 0.7797, f1: 0.7419, auc: 0.7945\n",
      "\n",
      "Fold 05: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 05 metrics -> acc: 0.6140, prec: 0.6000, rec: 0.7627, f1: 0.6716, auc: 0.6878\n",
      "\n",
      "=== Overall OOF Metrics ===\n",
      "{'accuracy': 0.6713286713286714, 'precision': 0.6419098143236074, 'recall': 0.8203389830508474, 'f1': 0.7202380952380952, 'auc': np.float64(0.7601909074221379)}\n",
      "\n",
      "Saved aggregated OOF -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\gaussiannb\\oof_predictions.csv\n",
      "Saved OOF metrics -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\gaussiannb\\oof_metrics.json\n",
      "Saved per-fold pipelines & OOF CSVs -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\gaussiannb\n",
      "\n",
      "Done. Paste the printed output here and I will prepare the next model (Logistic Regression) when you tell me to continue.\n"
     ]
    }
   ],
   "source": [
    "# Train GaussianNB on each fold (one-by-one baseline). Saves per-fold pipelines & OOF preds.\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "ROOT = Path(\"dreaddit_cv_raw_splits\")\n",
    "FOLDS_DIR = ROOT / \"folds_selected\"\n",
    "SAVE_ROOT = Path(\"Machine learning\") / \"models\" / \"gaussiannb\"   # per your request\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fold_dirs = sorted([p for p in FOLDS_DIR.glob(\"fold_*\") if p.is_dir()])\n",
    "if not fold_dirs:\n",
    "    raise FileNotFoundError(f\"No per-fold directories found in {FOLDS_DIR}. Run folds preparation first.\")\n",
    "\n",
    "oof_rows = []\n",
    "fold_summaries = []\n",
    "\n",
    "print(\"Found fold dirs:\", [p.name for p in fold_dirs])\n",
    "\n",
    "for fd in fold_dirs:\n",
    "    fold_name = fd.name  # fold_01 etc.\n",
    "    fold_no = fold_name.split(\"_\")[1]\n",
    "    # load arrays\n",
    "    train_X_path = fd / f\"fold_{fold_no}_train_selected.npy\"\n",
    "    val_X_path   = fd / f\"fold_{fold_no}_val_selected.npy\"\n",
    "    train_csv    = fd / f\"fold_{fold_no}_train_selected.csv\"\n",
    "    val_csv      = fd / f\"fold_{fold_no}_val_selected.csv\"\n",
    "\n",
    "    if not (train_X_path.exists() and val_X_path.exists() and train_csv.exists() and val_csv.exists()):\n",
    "        raise FileNotFoundError(f\"Missing files for {fold_name} in {fd}\")\n",
    "\n",
    "    X_tr = np.load(train_X_path)\n",
    "    X_val = np.load(val_X_path)\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    y_tr = df_tr['label'].values\n",
    "    y_val = df_val['label'].values\n",
    "    idx_val = df_val['orig_index'].values\n",
    "\n",
    "    print(f\"\\nFold {fold_no}: X_tr {X_tr.shape}, X_val {X_val.shape}, y_tr counts {np.bincount(y_tr)}, y_val counts {np.bincount(y_val)}\")\n",
    "\n",
    "    # train GaussianNB (no class_weight param for NB)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # preds\n",
    "    probs_val = clf.predict_proba(X_val)[:,1]  # probability for class 1\n",
    "    preds_val = (probs_val >= 0.5).astype(int)\n",
    "\n",
    "    # per-fold metrics\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    prec = precision_score(y_val, preds_val, zero_division=0)\n",
    "    rec = recall_score(y_val, preds_val, zero_division=0)\n",
    "    f1 = f1_score(y_val, preds_val, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_val, probs_val)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\" Fold {fold_no} metrics -> acc: {acc:.4f}, prec: {prec:.4f}, rec: {rec:.4f}, f1: {f1:.4f}, auc: {auc:.4f}\")\n",
    "\n",
    "    # save fold pipeline (just the classifier here)\n",
    "    fold_pipe_path = SAVE_ROOT / f\"fold_{fold_no}_pipeline.joblib\"\n",
    "    joblib.dump(clf, fold_pipe_path)\n",
    "\n",
    "    # save OOF preds for this fold\n",
    "    oof_df = pd.DataFrame({\n",
    "        \"orig_index\": idx_val,\n",
    "        \"true_label\": y_val,\n",
    "        \"prob_pos\": probs_val,\n",
    "        \"pred_label\": preds_val\n",
    "    })\n",
    "    oof_csv_path = SAVE_ROOT / f\"fold_{fold_no}_oof.csv\"\n",
    "    oof_df.to_csv(oof_csv_path, index=False)\n",
    "\n",
    "    fold_summaries.append({\n",
    "        \"fold\": fold_no,\n",
    "        \"train_rows\": X_tr.shape[0],\n",
    "        \"val_rows\": X_val.shape[0],\n",
    "        \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc,\n",
    "        \"pipeline_path\": str(fold_pipe_path),\n",
    "        \"oof_csv\": str(oof_csv_path)\n",
    "    })\n",
    "\n",
    "    # collect rows for global OOF\n",
    "    for i, idx in enumerate(idx_val):\n",
    "        oof_rows.append({\"orig_index\": int(idx), \"true_label\": int(y_val[i]), \"prob_pos\": float(probs_val[i]), \"pred_label\": int(preds_val[i])})\n",
    "\n",
    "# aggregate OOF\n",
    "oof_all = pd.DataFrame(oof_rows).sort_values(\"orig_index\").reset_index(drop=True)\n",
    "oof_all_path = SAVE_ROOT / \"oof_predictions.csv\"\n",
    "oof_all.to_csv(oof_all_path, index=False)\n",
    "\n",
    "# compute overall OOF metrics\n",
    "y_true = oof_all['true_label'].values\n",
    "y_pred = oof_all['pred_label'].values\n",
    "y_prob = oof_all['prob_pos'].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc}\n",
    "print(\"\\n=== Overall OOF Metrics ===\")\n",
    "print(metrics)\n",
    "\n",
    "# Save metrics and manifest\n",
    "import json\n",
    "metrics_path = SAVE_ROOT / \"oof_metrics.json\"\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "manifest_df = pd.DataFrame(fold_summaries)\n",
    "manifest_df.to_csv(SAVE_ROOT / \"folds_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved aggregated OOF ->\", oof_all_path.resolve())\n",
    "print(\"Saved OOF metrics ->\", metrics_path.resolve())\n",
    "print(\"Saved per-fold pipelines & OOF CSVs ->\", SAVE_ROOT.resolve())\n",
    "print(\"\\nDone. Paste the printed output here and I will prepare the next model (Logistic Regression) when you tell me to continue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0314763c-26e3-416f-87a0-58caeabca9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found fold dirs: ['fold_01', 'fold_02', 'fold_03', 'fold_04', 'fold_05']\n",
      "\n",
      "Fold 01: X_tr (457, 34), X_val (115, 34), y_tr counts [221 236], y_val counts [56 59]\n",
      " Fold 01 metrics -> acc: 0.6783, prec: 0.7037, rec: 0.6441, f1: 0.6726, auc: 0.8057\n",
      "\n",
      "Fold 02: X_tr (457, 34), X_val (115, 34), y_tr counts [221 236], y_val counts [56 59]\n",
      " Fold 02 metrics -> acc: 0.7217, prec: 0.6957, rec: 0.8136, f1: 0.7500, auc: 0.8208\n",
      "\n",
      "Fold 03: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 03 metrics -> acc: 0.7018, prec: 0.7119, rec: 0.7119, f1: 0.7119, auc: 0.7815\n",
      "\n",
      "Fold 04: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 04 metrics -> acc: 0.7982, prec: 0.7903, rec: 0.8305, f1: 0.8099, auc: 0.8666\n",
      "\n",
      "Fold 05: X_tr (458, 34), X_val (114, 34), y_tr counts [222 236], y_val counts [55 59]\n",
      " Fold 05 metrics -> acc: 0.6930, prec: 0.7069, rec: 0.6949, f1: 0.7009, auc: 0.7676\n",
      "\n",
      "=== Overall OOF Metrics ===\n",
      "{'accuracy': 0.7185314685314685, 'precision': 0.7218543046357616, 'recall': 0.7389830508474576, 'f1': 0.7303182579564489, 'auc': np.float64(0.8056537967325461)}\n",
      "\n",
      "Saved aggregated OOF -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\logreg\\oof_predictions.csv\n",
      "Saved OOF metrics -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\logreg\\oof_metrics.json\n",
      "Saved per-fold pipelines & OOF CSVs -> C:\\Users\\AYUSH SINGH\\Documents\\GitHub\\NervSightX\\Machine learning\\Machine learning\\models\\logreg\n",
      "\n",
      "Done. Paste the printed output here when complete and I will prepare the next model.\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression (class_weight='balanced') on each fold (one-by-one)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import json\n",
    "\n",
    "ROOT = Path(\"dreaddit_cv_raw_splits\")\n",
    "FOLDS_DIR = ROOT / \"folds_selected\"\n",
    "SAVE_ROOT = Path(\"Machine learning\") / \"models\" / \"logreg\"\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fold_dirs = sorted([p for p in FOLDS_DIR.glob(\"fold_*\") if p.is_dir()])\n",
    "if not fold_dirs:\n",
    "    raise FileNotFoundError(f\"No per-fold directories found in {FOLDS_DIR}. Run folds preparation first.\")\n",
    "\n",
    "oof_rows = []\n",
    "fold_summaries = []\n",
    "\n",
    "print(\"Found fold dirs:\", [p.name for p in fold_dirs])\n",
    "\n",
    "for fd in fold_dirs:\n",
    "    fold_name = fd.name  # fold_01 etc.\n",
    "    fold_no = fold_name.split(\"_\")[1]\n",
    "    # load arrays & csvs\n",
    "    train_X_path = fd / f\"fold_{fold_no}_train_selected.npy\"\n",
    "    val_X_path   = fd / f\"fold_{fold_no}_val_selected.npy\"\n",
    "    train_csv    = fd / f\"fold_{fold_no}_train_selected.csv\"\n",
    "    val_csv      = fd / f\"fold_{fold_no}_val_selected.csv\"\n",
    "\n",
    "    if not (train_X_path.exists() and val_X_path.exists() and train_csv.exists() and val_csv.exists()):\n",
    "        raise FileNotFoundError(f\"Missing files for {fold_name} in {fd}\")\n",
    "\n",
    "    X_tr = np.load(train_X_path)\n",
    "    X_val = np.load(val_X_path)\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    y_tr = df_tr['label'].values\n",
    "    y_val = df_val['label'].values\n",
    "    idx_val = df_val['orig_index'].values\n",
    "\n",
    "    print(f\"\\nFold {fold_no}: X_tr {X_tr.shape}, X_val {X_val.shape}, y_tr counts {np.bincount(y_tr)}, y_val counts {np.bincount(y_val)}\")\n",
    "\n",
    "    # Logistic Regression with balanced class weights\n",
    "    clf = LogisticRegression(penalty='l2', solver='liblinear', C=1.0, max_iter=2000, class_weight='balanced')\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # preds\n",
    "    probs_val = clf.predict_proba(X_val)[:,1]\n",
    "    preds_val = (probs_val >= 0.5).astype(int)\n",
    "\n",
    "    # per-fold metrics\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    prec = precision_score(y_val, preds_val, zero_division=0)\n",
    "    rec = recall_score(y_val, preds_val, zero_division=0)\n",
    "    f1 = f1_score(y_val, preds_val, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_val, probs_val)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\" Fold {fold_no} metrics -> acc: {acc:.4f}, prec: {prec:.4f}, rec: {rec:.4f}, f1: {f1:.4f}, auc: {auc:.4f}\")\n",
    "\n",
    "    # save fold pipeline\n",
    "    fold_pipe_path = SAVE_ROOT / f\"fold_{fold_no}_pipeline.joblib\"\n",
    "    joblib.dump(clf, fold_pipe_path)\n",
    "\n",
    "    # save per-fold OOF\n",
    "    oof_df = pd.DataFrame({\n",
    "        \"orig_index\": idx_val,\n",
    "        \"true_label\": y_val,\n",
    "        \"prob_pos\": probs_val,\n",
    "        \"pred_label\": preds_val\n",
    "    })\n",
    "    oof_csv_path = SAVE_ROOT / f\"fold_{fold_no}_oof.csv\"\n",
    "    oof_df.to_csv(oof_csv_path, index=False)\n",
    "\n",
    "    fold_summaries.append({\n",
    "        \"fold\": fold_no,\n",
    "        \"train_rows\": X_tr.shape[0],\n",
    "        \"val_rows\": X_val.shape[0],\n",
    "        \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc,\n",
    "        \"pipeline_path\": str(fold_pipe_path),\n",
    "        \"oof_csv\": str(oof_csv_path)\n",
    "    })\n",
    "\n",
    "    # collect OOF rows\n",
    "    for i, idx in enumerate(idx_val):\n",
    "        oof_rows.append({\"orig_index\": int(idx), \"true_label\": int(y_val[i]), \"prob_pos\": float(probs_val[i]), \"pred_label\": int(preds_val[i])})\n",
    "\n",
    "# aggregate OOF across folds\n",
    "oof_all = pd.DataFrame(oof_rows).sort_values(\"orig_index\").reset_index(drop=True)\n",
    "oof_all_path = SAVE_ROOT / \"oof_predictions.csv\"\n",
    "oof_all.to_csv(oof_all_path, index=False)\n",
    "\n",
    "# compute overall metrics\n",
    "y_true = oof_all['true_label'].values\n",
    "y_pred = oof_all['pred_label'].values\n",
    "y_prob = oof_all['prob_pos'].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc}\n",
    "print(\"\\n=== Overall OOF Metrics ===\")\n",
    "print(metrics)\n",
    "\n",
    "# Save metrics and manifest\n",
    "metrics_path = SAVE_ROOT / \"oof_metrics.json\"\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "manifest_df = pd.DataFrame(fold_summaries)\n",
    "manifest_df.to_csv(SAVE_ROOT / \"folds_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved aggregated OOF ->\", oof_all_path.resolve())\n",
    "print(\"Saved OOF metrics ->\", metrics_path.resolve())\n",
    "print(\"Saved per-fold pipelines & OOF CSVs ->\", SAVE_ROOT.resolve())\n",
    "print(\"\\nDone. Paste the printed output here when complete and I will prepare the next model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894f69f-88cf-48fa-b6c9-50810addc419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found fold dirs: ['fold_01', 'fold_02', 'fold_03', 'fold_04', 'fold_05']\n",
      "\n",
      "Fold 01: X_tr (457, 34), X_val (115, 34), y_tr counts [221 236], y_val counts [56 59]\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM (linear kernel) on each fold (one-by-one)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import json\n",
    "\n",
    "ROOT = Path(\"dreaddit_cv_raw_splits\")\n",
    "FOLDS_DIR = ROOT / \"folds_selected\"\n",
    "SAVE_ROOT = Path(\"Machine learning\") / \"models\" / \"svm\"\n",
    "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fold_dirs = sorted([p for p in FOLDS_DIR.glob(\"fold_*\") if p.is_dir()])\n",
    "if not fold_dirs:\n",
    "    raise FileNotFoundError(f\"No per-fold directories found in {FOLDS_DIR}. Run folds preparation first.\")\n",
    "\n",
    "oof_rows = []\n",
    "fold_summaries = []\n",
    "\n",
    "print(\"Found fold dirs:\", [p.name for p in fold_dirs])\n",
    "\n",
    "for fd in fold_dirs:\n",
    "    fold_name = fd.name  # fold_01 etc.\n",
    "    fold_no = fold_name.split(\"_\")[1]\n",
    "    # load arrays & csvs\n",
    "    train_X_path = fd / f\"fold_{fold_no}_train_selected.npy\"\n",
    "    val_X_path   = fd / f\"fold_{fold_no}_val_selected.npy\"\n",
    "    train_csv    = fd / f\"fold_{fold_no}_train_selected.csv\"\n",
    "    val_csv      = fd / f\"fold_{fold_no}_val_selected.csv\"\n",
    "\n",
    "    if not (train_X_path.exists() and val_X_path.exists() and train_csv.exists() and val_csv.exists()):\n",
    "        raise FileNotFoundError(f\"Missing files for {fold_name} in {fd}\")\n",
    "\n",
    "    X_tr = np.load(train_X_path)\n",
    "    X_val = np.load(val_X_path)\n",
    "    df_tr = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    y_tr = df_tr['label'].values\n",
    "    y_val = df_val['label'].values\n",
    "    idx_val = df_val['orig_index'].values\n",
    "\n",
    "    print(f\"\\nFold {fold_no}: X_tr {X_tr.shape}, X_val {X_val.shape}, y_tr counts {np.bincount(y_tr)}, y_val counts {np.bincount(y_val)}\")\n",
    "\n",
    "    # SVC with linear kernel and probability estimates (class_weight balanced)\n",
    "    clf = SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # preds\n",
    "    probs_val = clf.predict_proba(X_val)[:,1]\n",
    "    preds_val = (probs_val >= 0.5).astype(int)\n",
    "\n",
    "    # per-fold metrics\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    prec = precision_score(y_val, preds_val, zero_division=0)\n",
    "    rec = recall_score(y_val, preds_val, zero_division=0)\n",
    "    f1 = f1_score(y_val, preds_val, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_val, probs_val)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\" Fold {fold_no} metrics -> acc: {acc:.4f}, prec: {prec:.4f}, rec: {rec:.4f}, f1: {f1:.4f}, auc: {auc:.4f}\")\n",
    "\n",
    "    # save fold pipeline\n",
    "    fold_pipe_path = SAVE_ROOT / f\"fold_{fold_no}_pipeline.joblib\"\n",
    "    joblib.dump(clf, fold_pipe_path)\n",
    "\n",
    "    # save per-fold OOF\n",
    "    oof_df = pd.DataFrame({\n",
    "        \"orig_index\": idx_val,\n",
    "        \"true_label\": y_val,\n",
    "        \"prob_pos\": probs_val,\n",
    "        \"pred_label\": preds_val\n",
    "    })\n",
    "    oof_csv_path = SAVE_ROOT / f\"fold_{fold_no}_oof.csv\"\n",
    "    oof_df.to_csv(oof_csv_path, index=False)\n",
    "\n",
    "    fold_summaries.append({\n",
    "        \"fold\": fold_no,\n",
    "        \"train_rows\": X_tr.shape[0],\n",
    "        \"val_rows\": X_val.shape[0],\n",
    "        \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc,\n",
    "        \"pipeline_path\": str(fold_pipe_path),\n",
    "        \"oof_csv\": str(oof_csv_path)\n",
    "    })\n",
    "\n",
    "    # collect OOF rows\n",
    "    for i, idx in enumerate(idx_val):\n",
    "        oof_rows.append({\"orig_index\": int(idx), \"true_label\": int(y_val[i]), \"prob_pos\": float(probs_val[i]), \"pred_label\": int(preds_val[i])})\n",
    "\n",
    "# aggregate OOF across folds\n",
    "oof_all = pd.DataFrame(oof_rows).sort_values(\"orig_index\").reset_index(drop=True)\n",
    "oof_all_path = SAVE_ROOT / \"oof_predictions.csv\"\n",
    "oof_all.to_csv(oof_all_path, index=False)\n",
    "\n",
    "# compute overall metrics\n",
    "y_true = oof_all['true_label'].values\n",
    "y_pred = oof_all['pred_label'].values\n",
    "y_prob = oof_all['prob_pos'].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "metrics = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc}\n",
    "print(\"\\n=== Overall OOF Metrics ===\")\n",
    "print(metrics)\n",
    "\n",
    "# Save metrics and manifest\n",
    "metrics_path = SAVE_ROOT / \"oof_metrics.json\"\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "manifest_df = pd.DataFrame(fold_summaries)\n",
    "manifest_df.to_csv(SAVE_ROOT / \"folds_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved aggregated OOF ->\", oof_all_path.resolve())\n",
    "print(\"Saved OOF metrics ->\", metrics_path.resolve())\n",
    "print(\"Saved per-fold pipelines & OOF CSVs ->\", SAVE_ROOT.resolve())\n",
    "print(\"\\nDone. Paste the printed output here and I will prepare the next model when you say so.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d66db-9d74-42ed-a7ba-9a749ec62453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
